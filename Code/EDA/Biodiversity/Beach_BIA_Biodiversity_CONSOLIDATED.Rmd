---
title: "Beach BIA — Biodiversity (Consolidated)"
author: "Biodiversity Group"
date: "`r format(Sys.Date())`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE, warning = FALSE)

suppressPackageStartupMessages({
  library(sf); library(dplyr); library(readr); library(stringr)
  library(janitor); library(glue); library(leaflet); library(purrr)
  library(ggplot2); library(lubridate); library(tibble); library(tidyr)
  library(htmlwidgets); library(rlang)
})

# ---------------- Parameters ----------------
AOI_BUFFER_M <- 30              # AOI buffer distance (meters)
WATER_BUF_M  <- 20              # Near-water buffer (meters)
START_DATE   <- as.Date("2020-01-01")

# ---------------- Paths & helpers ----------------
OUT_DIR <- file.path(getwd(), "outputs")
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)

msg <- function(...) message(glue::glue(...))

# Search across multiple roots
DATA_DIRS <- unique(c(
  getwd(),
  file.path(getwd(), "Dataset"),
  file.path(getwd(), "data"),
  "/mnt/data"
))

msg("Search roots:\n{paste0(' - ', DATA_DIRS, collapse = '\n')}")

# Find the first file matching a regex pattern across all roots
find_first <- function(pattern, required = TRUE) {
  files <- unlist(lapply(DATA_DIRS, function(root) {
    list.files(root, pattern = pattern, recursive = TRUE, full.names = TRUE)
  }))
  if (length(files)) return(files[1])
  if (required) stop(glue("Missing file for pattern: {pattern}"))
  NA_character_
}

# Find a vector dataset (prefer GeoJSON; else complete SHP)
find_vector <- function(base_pat, prefer_geojson = TRUE, required = TRUE){
  if (prefer_geojson) {
    gj <- unlist(lapply(DATA_DIRS, function(root) {
      list.files(root, pattern = glue("{base_pat}.*\\.geojson$"), recursive = TRUE, full.names = TRUE)
    }))
    if (length(gj)) return(gj[1])
  }
  shp <- find_first(glue("{base_pat}.*\\.shp$"), required = required)
  if (is.na(shp)) return(NA_character_)
  stem <- sub("\\.shp$", "", shp, ignore.case = TRUE)
  need <- paste0(stem, c(".shx", ".dbf"))
  if (!all(file.exists(need))) stop(glue("Incomplete SHP for {basename(shp)}"))
  shp
}

# Read sf and ensure EPSG:4326
safe_read_sf <- function(f){
  x <- suppressMessages(st_read(f, quiet = TRUE))
  if (!is.na(st_crs(x)) && st_crs(x)$epsg != 4326) x <- st_transform(x, 4326)
  x
}

# turn off s2 globally for this knit (avoid spherical union issues)
sf::sf_use_s2(FALSE)
```


# 1) Resolve files
```{r}
# Prefer the newest iNat CSV (631589), then 624727, then a generic observations.csv

inat_csv <- NA_character_
for (pat in c("observations-631589\\.csv$", "observations-624727\\.csv$", "observations\\.csv$")) {
candidate <- tryCatch(find_first(pat, required = FALSE), error = function(e) NA_character_)
if (!is.na(candidate)) { inat_csv <- candidate; break }
}
if (is.na(inat_csv)) stop("iNaturalist CSV not found. Expected e.g. observations-631589.csv")

resolved <- list(
inat_csv = inat_csv,
bia      = find_vector("Business.*Areas.*4326"),
green    = find_vector("Green.*Spaces.*4326"),
neigh    = find_vector("Neighbourhoods.*4326"),
trees    = find_vector("TOPO_TREE_WGS84",      prefer_geojson = FALSE),
water    = find_vector("TOPO_Waterbody_WGS84", prefer_geojson = FALSE),
woodbine = {
wb <- unlist(lapply(DATA_DIRS, function(root)
list.files(root, pattern="WoodbineBeach.shp$", recursive=TRUE, full.names=TRUE)))
if (length(wb)) wb[1] else NA_character_
}
)

msg("Resolved paths:\n{paste(capture.output(str(resolved)), collapse = '\n')}")

```

# 2) Build AOI (BIA ∪ Woodbine ∪ Neighbourhood 'The Beaches') + cache layers
```{r}
# Cache targets for faster re-runs
inat_gj <- file.path(OUT_DIR,"inat_aoi.geojson")
tree_gj <- file.path(OUT_DIR,"trees_aoi.geojson")
aoi_gj  <- file.path(OUT_DIR,"aoi_union_buffer.geojson")

use_cached <- file.exists(inat_gj) && file.exists(tree_gj) && file.exists(aoi_gj)

if (use_cached){
  msg("✅ Using cached GeoJSON in outputs/")
  inat_aoi  <- safe_read_sf(inat_gj)
  trees_aoi <- safe_read_sf(tree_gj)
  aoi_buf   <- safe_read_sf(aoi_gj)
} else {
  msg("ℹ Rebuilding from raw data ...")

  # ---- iNaturalist points ----
  inat <- read_csv(resolved$inat_csv, show_col_types = FALSE) |>
    clean_names() |>
    mutate(
      latitude  = as.numeric(latitude),
      longitude = as.numeric(longitude)
    ) |>
    filter(!is.na(latitude), !is.na(longitude),
           between(latitude,-90,90), between(longitude,-180,180))
  inat_sf <- st_as_sf(inat, coords = c("longitude","latitude"), crs = 4326, remove = FALSE)

  # ---- Base layers ----
  bia   <- safe_read_sf(resolved$bia)
  green <- safe_read_sf(resolved$green)
  trees <- safe_read_sf(resolved$trees)
  neigh <- safe_read_sf(resolved$neigh)

  # ---- Pick Beach BIA by name (robust) ----
  bia_chr <- names(bia)[vapply(bia, function(x) is.character(x)||is.factor(x), logical(1))]
  pat_bia <- regex("(^|\\b)(the\\s*beach|the\\s*beaches|beach|beaches)(\\b|$)", ignore_case = TRUE)
  hits    <- sapply(bia_chr, function(col) sum(str_detect(as.character(bia[[col]]), pat_bia), na.rm = TRUE))
  beach_bia <- if (length(hits) && max(hits) > 0) {
    best <- names(which.max(hits)); bia[str_detect(as.character(bia[[best]]), pat_bia), ]
  } else {
    warning("No BIA name match; using all BIA."); bia
  }

  # ---- Woodbine polygon (from Green Spaces or dedicated SHP) ----
  beach <- if (!is.na(resolved$woodbine)) {
    tryCatch(safe_read_sf(resolved$woodbine), error = function(e) NULL)
  } else NULL
  if (is.null(beach) || nrow(beach) == 0){
    gr_chr <- names(green)[vapply(green, function(x) is.character(x)||is.factor(x), logical(1))]
    idx <- Reduce(`|`, lapply(gr_chr, function(col) str_detect(tolower(green[[col]]), "woodbine")))
    beach <- green[idx,]
    if (nrow(beach) == 0) stop("No 'Woodbine' polygon found in Green Spaces.")
  }

  # ---- Neighbourhood: 'The Beaches' (by name; fallback to code 93 if present) ----
  nb_chr  <- names(neigh)[vapply(neigh, function(x) is.character(x)||is.factor(x), logical(1))]
  pat_nb  <- regex("(^|\\b)the\\s*beaches(\\b|$)", ignore_case = TRUE)
  nb_hits <- sapply(nb_chr, function(col) sum(str_detect(as.character(neigh[[col]]), pat_nb), na.rm = TRUE))
  neigh_beaches <- if (length(nb_hits) && max(nb_hits) > 0) {
    best <- names(which.max(nb_hits)); neigh[str_detect(as.character(neigh[[best]]), pat_nb), ]
  } else if ("X_id1" %in% names(neigh) && any(neigh$X_id1 == 93, na.rm = TRUE)) {
    neigh %>% dplyr::filter(.data$X_id1 == 93)
  } else {
    warning("Could not find neighbourhood 'The Beaches' by name or code; skipping.")
    NULL
  }

  # ---- AOI = union(BIA, Woodbine, The Beaches) + buffer (planar) ----
  sanitize <- function(g) {
    g <- st_make_valid(g)
    suppressWarnings(st_collection_extract(g, "POLYGON"))
  }
  parts <- list(sanitize(beach_bia), sanitize(beach))
  if (!is.null(neigh_beaches) && nrow(neigh_beaches) > 0) parts <- c(parts, list(sanitize(neigh_beaches)))

  # Do the union in a projected CRS to avoid s2 entirely
  geoms_4326 <- do.call(c, lapply(parts, st_geometry))
  geoms_proj <- st_transform(geoms_4326, 32617)
  aoi_comb   <- st_combine(geoms_proj)
  aoi_planar <- st_union(aoi_comb)
  aoi_buf    <- st_buffer(aoi_planar, AOI_BUFFER_M) |> st_transform(4326)

  # ---- Filter layers by AOI ----
  inat_aoi  <- st_filter(inat_sf, aoi_buf)
  trees_aoi <- st_filter(trees,   aoi_buf)

  # ---- Write cache ----
  st_write(inat_aoi,  inat_gj, delete_dsn = TRUE, quiet = TRUE)
  st_write(trees_aoi, tree_gj, delete_dsn = TRUE, quiet = TRUE)
  st_write(aoi_buf,   aoi_gj,  delete_dsn = TRUE, quiet = TRUE)

  # Keep key polygons in the session for later sections
  assign("beach_bia", beach_bia, envir = .GlobalEnv)
  assign("beach",     beach,     envir = .GlobalEnv)
  if (!is.null(neigh_beaches)) assign("neigh_beaches", neigh_beaches, envir = .GlobalEnv)
}

# If we came from cache, (re)load polygons for later summaries
if (!exists("beach_bia") || !exists("beach")) {
  bia   <- safe_read_sf(resolved$bia)
  green <- safe_read_sf(resolved$green)
  bia_chr <- names(bia)[vapply(bia, function(x) is.character(x)||is.factor(x), logical(1))]
  pat_bia <- regex("(^|\\b)(the\\s*beach|the\\s*beaches|beach|beaches)(\\b|$)", ignore_case = TRUE)
  hits    <- sapply(bia_chr, function(col) sum(str_detect(as.character(bia[[col]]), pat_bia), na.rm = TRUE))
  beach_bia <- if (length(hits) && max(hits) > 0) {
    best <- names(which.max(hits)); bia[str_detect(as.character(bia[[best]]), pat_bia), ]
  } else bia

  gr_chr <- names(green)[vapply(green, function(x) is.character(x)||is.factor(x), logical(1))]
  idx <- Reduce(`|`, lapply(gr_chr, function(col) str_detect(tolower(green[[col]]), "woodbine")))
  beach <- green[idx,]
}
```

# 3) Classify iNat categories + QA (dedupe, optional research grade)
```{r}
# Robust iconic class (supports both column names)

iconic_candidates <- intersect(c("iconic_taxon_name", "taxon_iconic_name"),
names(inat_aoi))

inat_clean <- inat_aoi %>%
mutate(
iconic_tmp = if (length(iconic_candidates) > 0) {
dplyr::coalesce(!!! rlang::syms(iconic_candidates))
} else NA_character_,
category = case_when(
str_detect(iconic_tmp, regex("Plantae",  TRUE)) ~ "Plants",
str_detect(iconic_tmp, regex("Aves",     TRUE)) ~ "Birds",
str_detect(iconic_tmp, regex("Insecta",  TRUE)) ~ "Insects",
str_detect(iconic_tmp, regex("Mammalia", TRUE)) ~ "Mammals",
str_detect(iconic_tmp, regex("Reptilia", TRUE)) ~ "Reptiles",
str_detect(iconic_tmp, regex("Arachnida",TRUE)) ~ "Spiders",
TRUE ~ "Other"
)
) %>% select(-iconic_tmp)

# De-duplicate by ID if present (safe for sf with tidy-eval)

id_col <- intersect(c("id", "observation_id"), names(inat_clean))[1]
if (!is.na(id_col) && nzchar(id_col)) {
id_sym <- rlang::sym(id_col)
inat_clean <- inat_clean %>% arrange(!!id_sym) %>% distinct(!!id_sym, .keep_all = TRUE)
}

# Optional research-grade slice (kept for convenience)

inat_research <- if ("quality_grade" %in% names(inat_clean)) {
filter(inat_clean, quality_grade == "research")
} else inat_clean

table(inat_clean$category)
```

# 4) Core stats + CSV exports
```{r}
AREA_CRS <- 32617
area_ha <- aoi_buf |> st_transform(AREA_CRS) |> st_area() |> as.numeric() / 10000
species_n <- if ("scientific_name" %in% names(inat_clean))
n_distinct(inat_clean$scientific_name) else NA_integer_

summary_tbl <- tibble(
total_obs      = nrow(inat_clean),
unique_species = species_n,
tree_points    = nrow(trees_aoi),
area_ha        = round(sum(area_ha), 2),
species_per_ha = round(species_n / sum(area_ha), 3),
aoi_buffer_m   = AOI_BUFFER_M
)
summary_tbl
write_csv(summary_tbl, file.path(OUT_DIR, "bio_summary_final.csv"))

top_species_tbl <- inat_clean |> st_drop_geometry() |> count(scientific_name, sort=TRUE) |> slice_head(n=10)
top_observers_tbl <- inat_clean |> st_drop_geometry() |> count(user_login, sort=TRUE) |> slice_head(n=10)
write_csv(top_species_tbl,  file.path(OUT_DIR,"top_species.csv"))
write_csv(top_observers_tbl,file.path(OUT_DIR,"top_observers.csv"))

if ("observed_on" %in% names(inat_clean)) {
monthly <- inat_clean |> st_drop_geometry() |>
mutate(date = as.Date(observed_on)) |> filter(!is.na(date), date >= START_DATE) |>
count(month = lubridate::floor_date(date, "month"))
ggplot(monthly, aes(month, n)) + geom_col() +
scale_x_date(date_labels="%Y-%m", date_breaks="1 month", expand=c(0.01,0.01)) +
labs(x="Month", y="Observations", title="iNaturalist observations per month") +
theme_minimal() + theme(axis.text.x=element_text(angle=45, hjust=1))
}

cat_summary <- inat_clean |> st_drop_geometry() |> count(category, name="observations") |> arrange(desc(observations))
write_csv(cat_summary, file.path(OUT_DIR,"category_summary.csv"))
```

# 5) Multi-area summary (BIA vs Woodbine vs Neighbourhood vs AOI)
```{r}
summarise_area <- function(name, poly){
poly <- st_make_valid(poly)
a_ha <- st_area(st_transform(poly, AREA_CRS)) |> as.numeric() / 10000
inat_s  <- st_filter(inat_clean, poly)
trees_s <- st_filter(trees_aoi,   poly)
tibble(
area            = name,
total_obs       = nrow(inat_s),
unique_species  = if ("scientific_name" %in% names(inat_s)) n_distinct(inat_s$scientific_name) else NA_integer_,
tree_points     = nrow(trees_s),
area_ha         = round(sum(a_ha), 2),
species_per_ha  = round(n_distinct(inat_s$scientific_name) / sum(a_ha), 3)
)
}

areas_list <- list(
"Beach BIA" = beach_bia,
"Woodbine Beach" = beach,
"AOI buffer (union)" = aoi_buf
)

if (exists("neigh_beaches") && nrow(neigh_beaches)>0) {
areas_list[["The Beaches (Neighbourhood)"]] <- neigh_beaches
}

summary_by_area <- bind_rows(purrr::imap(areas_list, ~ summarise_area(.y, .x)))
summary_by_area
write_csv(summary_by_area, file.path(OUT_DIR,"bio_summary_by_area.csv"))
```

# 6) Neighbourhood richness choropleth (within AOI)
```{r}
neigh <- safe_read_sf(resolved$neigh)
neigh_clip <- suppressWarnings(st_intersection(st_make_valid(neigh), st_make_valid(aoi_buf)))

# Guess name column

neigh_name_col <- names(neigh_clip)[str_detect(names(neigh_clip), regex("NAME|NEIGH|AREA", TRUE))][1]
if (is.na(neigh_name_col)) neigh_name_col <- names(neigh_clip)[1]

inat_neigh <- st_join(inat_clean, neigh_clip, left = FALSE)

obs_by_neigh <- inat_neigh %>% st_drop_geometry() %>% count(neigh = .data[[neigh_name_col]], name = "obs")
sp_by_neigh  <- inat_neigh %>% st_drop_geometry() %>% group_by(neigh = .data[[neigh_name_col]]) %>%
summarise(unique_species = n_distinct(.data$scientific_name), .groups = "drop")

neigh_area <- neigh_clip %>%
mutate(area_ha = as.numeric(st_area(st_transform(., AREA_CRS)))/10000) %>%
st_drop_geometry() %>% select(neigh = .data[[neigh_name_col]], area_ha)

neigh_summary <- obs_by_neigh %>% left_join(sp_by_neigh, by="neigh") %>% left_join(neigh_area, by="neigh") %>%
mutate(species_per_ha = round(unique_species/area_ha, 3)) %>% arrange(desc(unique_species))
write_csv(neigh_summary, file.path(OUT_DIR, "neighbourhood_biodiversity_summary.csv"))
neigh_summary

neigh_poly_metric <- neigh_clip %>% left_join(neigh_summary, by = setNames("neigh", neigh_name_col)) %>%
mutate(label_rich = paste0(
.data[[neigh_name_col]],
"<br>Species: ", ifelse(is.na(unique_species), 0, unique_species),
"<br>Area(ha): ", ifelse(is.na(area_ha), NA, round(area_ha,1)),
"<br>Sp/ha: ", ifelse(is.na(species_per_ha), NA, species_per_ha)
))

pal_rich <- colorBin("YlGnBu", neigh_poly_metric$unique_species, bins = 6, na.color = "#cccccc")

leaflet(options = leafletOptions(minZoom = 10)) %>%
addProviderTiles("CartoDB.Positron") %>%
addPolygons(data = neigh_poly_metric, fillColor = ~pal_rich(unique_species),
color = "#555", weight = 1, fillOpacity = 0.6, label = ~label_rich) %>%
addLegend("bottomright", pal = pal_rich, values = neigh_poly_metric$unique_species,
title = "Unique species (neighbourhood)")
```

# 7) Near-water analysis
```{r}
water <- safe_read_sf(resolved$water)
water_clip <- suppressWarnings(st_intersection(st_make_valid(water), st_make_valid(aoi_buf)))
water_buf  <- st_transform(water_clip, AREA_CRS) %>% st_buffer(WATER_BUF_M) %>% st_transform(4326)

near_flag <- inat_clean %>%
mutate(near_water = lengths(st_intersects(., water_buf)) > 0) %>%
st_drop_geometry() %>%
count(category, near_water) %>%
pivot_wider(names_from = near_water, values_from = n, values_fill = 0, names_prefix = "is_") %>%
transmute(category, near = `is_TRUE`, away = `is_FALSE`, share_near = round(near/(near+away), 3))

overall_share_near <- round(sum(near_flag$near) / sum(near_flag$near + near_flag$away), 3)
write_csv(near_flag, file.path(OUT_DIR, "near_water_by_category.csv"))
tibble(overall_share_near)
near_flag
```

# 8) Maps — category layers + trees
```{r}
m <- leaflet(options = leafletOptions(minZoom=10)) %>%
addProviderTiles("CartoDB.Positron") %>%
addPolygons(data=aoi_buf, label="AOI (union) buffer", color="#444", weight=2, fillOpacity=0.05) %>%
addCircleMarkers(data=filter(inat_clean, category=="Plants"),  radius=2, color="#2ca25f", stroke=FALSE, fillOpacity=0.9, group="Plants") %>%
addCircleMarkers(data=filter(inat_clean, category=="Birds"),   radius=2, color="#3182bd", stroke=FALSE, fillOpacity=0.9, group="Birds")  %>%
addCircleMarkers(data=filter(inat_clean, category=="Insects"), radius=2, color="#fd8d3c", stroke=FALSE, fillOpacity=0.9, group="Insects")%>%
addCircleMarkers(data=filter(inat_clean, category=="Mammals"), radius=2, color="#756bb1", stroke=FALSE, fillOpacity=0.9, group="Mammals")%>%
addCircleMarkers(data=filter(inat_clean, category=="Reptiles"),radius=2, color="#41ab5d", stroke=FALSE, fillOpacity=0.9, group="Reptiles")%>%
addCircleMarkers(data=filter(inat_clean, category=="Spiders"), radius=2, color="#636363", stroke=FALSE, fillOpacity=0.9, group="Spiders") %>%
addCircleMarkers(data=filter(inat_clean, category=="Other"),   radius=2, color="#969696", stroke=FALSE, fillOpacity=0.8, group="Other")   %>%
addCircleMarkers(data=trees_aoi, radius=2, color="green", stroke=FALSE, fillOpacity=0.6, group="Trees") %>%
addLayersControl(overlayGroups=c("Plants","Birds","Insects","Mammals","Reptiles","Spiders","Other","Trees"),
options=layersControlOptions(collapsed=FALSE)) %>%
addLegend("bottomright",
colors=c("#2ca25f","#3182bd","#fd8d3c","#756bb1","#41ab5d","#636363","#969696","green"),
labels=c("Plants","Birds","Insects","Mammals","Reptiles","Spiders","Other","Trees"),
title="Layers")
m
saveWidget(m, file.path(OUT_DIR,"map_categories_and_trees.html"), selfcontained=TRUE)

if (requireNamespace("leaflet.extras", quietly = TRUE)) {
m_heat <- leaflet(options = leafletOptions(minZoom=10)) %>%
addProviderTiles("CartoDB.Positron") %>%
addPolygons(data=aoi_buf, label="AOI (union) buffer", color="#444", weight=2, fillOpacity=0.05) %>%
leaflet.extras::addHeatmap(data = inat_clean, blur = 15, max = 0.6, radius = 10)
saveWidget(m_heat, file.path(OUT_DIR,"map_heat.html"), selfcontained=TRUE)
}
```

# 9) Map — top-10 species (each as a layer)
```{r}
top10_species <- inat_clean |> st_drop_geometry() |> count(scientific_name, sort=TRUE) |> slice_head(n=10) |> pull(scientific_name)
inat_top <- filter(inat_clean, scientific_name %in% top10_species)

pal_sp <- colorFactor("Set1", domain = sort(unique(st_drop_geometry(inat_top)$scientific_name)))
popup_sp <- ~paste0(
"<b>", scientific_name, "</b>",
if ("observed_on" %in% names(inat_top)) paste0("<br/>Date: ", observed_on) else "",
if ("user_login"  %in% names(inat_top)) paste0("<br/>Observer: ", user_login) else ""
)
species_groups <- sort(unique(st_drop_geometry(inat_top)$scientific_name))

m_top <- leaflet(options = leafletOptions(minZoom=10)) %>%
addProviderTiles("CartoDB.Positron") %>%
addPolygons(data=aoi_buf, label="AOI (union) buffer", color="#444", weight=2, fillOpacity=0.05)

for (sp in species_groups) {
m_top <- m_top %>%
addCircleMarkers(
data = filter(inat_top, scientific_name == sp),
radius = 3, color = pal_sp(sp), stroke = FALSE, fillOpacity = 0.9,
popup = popup_sp, group = sp,
clusterOptions = markerClusterOptions(spiderfyOnMaxZoom = TRUE)
)
}

m_top <- m_top %>%
addLayersControl(overlayGroups = c(species_groups),
options = layersControlOptions(collapsed = FALSE)) %>%
addLegend("bottomright", pal = pal_sp, values = ~scientific_name,
data = st_drop_geometry(inat_top), title = "Top 10 species")

m_top
saveWidget(m_top, file.path(OUT_DIR,"map_top10_species.html"), selfcontained=TRUE)
```


# 10) Map — per-year layers
```{r}
if ("observed_on" %in% names(inat_clean)) {
inat_year <- inat_clean %>% mutate(year_obs = format(as.Date(observed_on), "%Y")) %>%
filter(!is.na(year_obs))

years <- sort(unique(st_drop_geometry(inat_year)$year_obs))
pal_year <- colorFactor("magma", domain = years)

m_year <- leaflet() %>% addProviderTiles("CartoDB.Positron") %>%
addPolygons(data = aoi_buf, color = "lightblue", weight = 2, fillOpacity = 0.05)

for (yy in years) {
m_year <- m_year %>% addCircles(
data  = subset(inat_year, year_obs == yy),
group = yy, color = ~pal_year(year_obs),
radius = 1, opacity = 1, weight = 3
)
}

m_year <- m_year %>% addLegend("bottomright", pal = pal_year, values = years, opacity = 1) %>%
addLayersControl(position = "topright", overlayGroups = years, options = layersControlOptions(collapsed = FALSE))

m_year
saveWidget(m_year, file.path(OUT_DIR,"map_by_year.html"), selfcontained=TRUE)
}
```

# 11) Top-5 species by area (tables)
```{r}
areas_for_table <- list(
`Beach BIA` = beach_bia,
`Woodbine Beach` = beach,
`AOI buffer (union)` = aoi_buf
)
if (exists("neigh_beaches") && nrow(neigh_beaches)>0) {
areas_for_table[["The Beaches (Neighbourhood)"]] <- neigh_beaches
}

topN_area <- function(poly, N=5){
pts <- st_filter(inat_clean, poly)
pts %>% st_drop_geometry() %>% count(scientific_name, sort=TRUE) %>% slice_head(n=N)
}

top_by_area <- purrr::imap(areas_for_table, ~ topN_area(.x, N=5) %>% mutate(area = .y)) %>%
bind_rows() %>% relocate(area)
write_csv(top_by_area, file.path(OUT_DIR, "top5_species_by_area.csv"))
top_by_area
```

# 12) Checklist + mini data dictionary
```{r}
tibble(
item = c(
"AOI = union(BIA, Woodbine, The Beaches) + buffer",
"CRS unified (EPSG:4326)",
"iNat QA (dedupe) + optional research-grade view",
"iNat + Trees filtered by AOI",
"Monthly trend chart",
"Category layers map (+ optional heatmap)",
"Multi-area summary (BIA/Woodbine/Neighbourhood/AOI)",
"Neighbourhood richness choropleth",
"Near-water category shares",
"Top-10 species layered map",
"Per-year layered map",
"Top-5 species by area tables",
"All outputs saved in /outputs"
),
done = TRUE
)

dict <- tibble::tribble(
~file, ~column, ~meaning,
"bio_summary_final.csv","total_obs","iNat obs inside AOI",
"bio_summary_final.csv","unique_species","distinct scientific_name",
"bio_summary_final.csv","tree_points","tree records inside AOI",
"bio_summary_final.csv","area_ha","AOI area (hectares)",
"bio_summary_final.csv","species_per_ha","unique_species / area_ha",
"bio_summary_final.csv","aoi_buffer_m","AOI buffer used (meters)",
"neighbourhood_biodiversity_summary.csv","neigh","neighbourhood name",
"neighbourhood_biodiversity_summary.csv","unique_species","species within neighbourhood∩AOI",
"neighbourhood_biodiversity_summary.csv","area_ha","neighbourhood area in AOI (ha)",
"neighbourhood_biodiversity_summary.csv","species_per_ha","unique_species / area_ha",
"near_water_by_category.csv","category","Plants/Birds/Insects/Mammals/Reptiles/Spiders/Other",
"near_water_by_category.csv","near, away","counts within vs. outside WATER_BUF_M",
"near_water_by_category.csv","share_near","near / (near+away)",
"top5_species_by_area.csv","area","BIA / Woodbine / Neighbourhood / AOI",
"top5_species_by_area.csv","scientific_name","species name",
"top5_species_by_area.csv","n","observation count"
)
write_csv(dict, file.path(OUT_DIR, "outputs_data_dictionary.csv"))
```
