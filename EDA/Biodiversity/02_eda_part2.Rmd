---
title: "Beach BIA â€” Biodiversity EDA (Part 2)"
author: "Beach BIA Biodiversity Team"
date: "`r format(Sys.Date())`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r}
knitr::opts_chunk$set(echo = TRUE, message = TRUE, warning = FALSE)
```

```{r file-overview, include=FALSE}
# Purpose: Additional EDA (top species/observers, temporal pattern, and interactive map) using cached AOI-filtered layers when available.
# Inputs : outputs/*.geojson caches OR raw datasets (same patterns as 01_data_eda.Rmd).
# Outputs: outputs/top_species.csv, outputs/top_observers.csv, outputs/bio_summary_final.csv (and maps in the knitted HTML).
# Notes  : Uses cached GeoJSON in outputs/ when present to speed up reruns; CRS standardized to EPSG:4326.
# Author : Beach BIA Biodiversity Team (edited/commented by Peter)
```


#1. Load Packages & Paths
```{r}
suppressPackageStartupMessages({
  library(sf)
  library(dplyr)
  library(readr)
  library(stringr)
  library(janitor)
  library(glue)
  library(leaflet)
  library(purrr)
  library(ggplot2)
  library(lubridate)
})

DATA_DIR <- getwd()
OUT_DIR  <- file.path(DATA_DIR, "outputs")
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)
# msg(): lightweight wrapper for glue::glue() + message() to keep logging consistent.

msg <- function(...) message(glue::glue(...))
msg("Data dir: {DATA_DIR}")
msg("Outputs : {normalizePath(OUT_DIR)}")

```

#2. Load prepared GeoJSONs or rebuild
```{r}
# --- Cache strategy ---
# If outputs/*.geojson exist from a previous run, we load them to avoid re-reading
# all raw datasets. Otherwise we rebuild AOI + filtered layers and write caches.

# --- try to load prepared files ---

inat_gj  <- file.path(OUT_DIR, "inat_beach.geojson")
tree_gj  <- file.path(OUT_DIR, "trees_beach.geojson")
aoi_gj   <- file.path(OUT_DIR, "Beach_BIA_area.geojson")

use_cached <- file.exists(inat_gj) && file.exists(tree_gj) && file.exists(aoi_gj)
# safe_read_sf(): wrapper around sf::st_read() that normalizes CRS to EPSG:4326 (WGS84) when possible.
# This helps ensure all layers align for filtering and mapping.

safe_read_sf <- function(f){
  x <- suppressMessages(sf::st_read(f, quiet = TRUE))
  if (!is.na(sf::st_crs(x)) && st_crs(x)$epsg != 4326) x <- sf::st_transform(x, 4326)
  x
}

if (use_cached) {
  msg("âœ… Using cached GeoJSON from outputs/")
  inat_beach  <- safe_read_sf(inat_gj)
  trees_beach <- safe_read_sf(tree_gj)
  aoi_buf     <- safe_read_sf(aoi_gj)
} else {
  msg("â„¹ No cached GeoJSON found. Rebuilding from raw datasetsâ€¦")

  # --- resolvers (prefer .geojson; else complete .shp) ---
# find_vector(): locate a spatial layer by filename pattern.
# Prefers GeoJSON when available; otherwise selects a complete Shapefile (requires .shp + .shx + .dbf).
# Returns a single file path to be passed into sf::st_read().
  find_vector <- function(base_pat, prefer_geojson = TRUE) {
    if (prefer_geojson) {
      gj <- list.files(DATA_DIR, pattern = paste0(base_pat, ".*\\.geojson$"),
                       recursive = TRUE, full.names = TRUE)
      if (length(gj) > 0) return(gj[1])
    }
    shp <- list.files(DATA_DIR, pattern = paste0(base_pat, ".*\\.shp$"),
                      recursive = TRUE, full.names = TRUE)
    if (length(shp) == 0) stop(glue("Vector not found: {base_pat}(.geojson|.shp)"))
    complete <- function(p){
      b <- sub("\\.shp$", "", p, ignore.case = TRUE)
      file.exists(paste0(b, ".shx")) && file.exists(paste0(b, ".dbf"))
    }
    ok <- shp[vapply(shp, complete, logical(1))]
    if (length(ok) == 0) stop(glue("Only incomplete SHP for: {base_pat}"))
    ok[1]
  }

  inat_path  <- list.files(DATA_DIR, pattern = "observations-624727\\.csv$",
                           recursive = TRUE, full.names = TRUE)[1]
  if (is.na(inat_path)) stop("iNat CSV not found.")

  bia_path   <- find_vector("Business.*Areas.*4326")
  green_path <- find_vector("Green.*Spaces.*4326")
  tree_path  <- find_vector("TOPO_TREE_WGS84",      prefer_geojson = FALSE)
  watr_path  <- find_vector("TOPO_Waterbody_WGS84", prefer_geojson = FALSE)
  bech_path  <- find_vector("WoodbineBeach")

  # --- read ---
  inat  <- readr::read_csv(inat_path, show_col_types = FALSE) %>%
    janitor::clean_names() %>%
    mutate(latitude = as.numeric(latitude), longitude = as.numeric(longitude)) %>%
    filter(!is.na(latitude), !is.na(longitude),
           between(latitude, -90, 90), between(longitude, -180, 180))
  inat_sf <- st_as_sf(inat, coords = c("longitude", "latitude"), crs = 4326, remove = FALSE)

  bia   <- safe_read_sf(bia_path)
  green <- safe_read_sf(green_path)
  trees <- safe_read_sf(tree_path)
  beach <- tryCatch(safe_read_sf(bech_path), error = function(e) NULL)

  # --- robust BIA pick by name ---
  char_cols <- names(bia)[vapply(bia, function(x) is.character(x) || is.factor(x), logical(1))]
  pat <- stringr::regex("(^|\\b)(the\\s+beach|beaches|beach)(\\b|$)", ignore_case = TRUE)
  hits <- sapply(char_cols, function(col) sum(str_detect(as.character(bia[[col]]), pat), na.rm = TRUE))
  if (length(hits) > 0 && max(hits) > 0) {
    best_col <- names(which.max(hits))
    beach_bia <- bia[str_detect(as.character(bia[[best_col]]), pat), ]
  } else {
    beach_bia <- bia
    warning("No BIA name matched 'Beach/Beaches/The Beach'. Using full BIA.")
  }

  # --- Woodbine fallback from Green Spaces ---
  if (is.null(beach) || nrow(beach) == 0) {
    cc <- names(green)[vapply(green, function(x) is.character(x) || is.factor(x), logical(1))]
    idx <- Reduce(`|`, lapply(cc, function(col) str_detect(tolower(green[[col]]), "woodbine")))
    beach <- green[idx, ]
    if (nrow(beach) == 0) stop("No 'Woodbine' polygon in Green Spaces.")
  }

  # --- AOI union + 30m buffer ---
  beach_bia <- st_make_valid(beach_bia); beach <- st_make_valid(beach)
  aoi <- st_union(beach_bia, beach)
  aoi_buf <- aoi |> st_transform(32617) |> st_buffer(30) |> st_transform(4326)

  # --- filter (intersects) ---
  inat_beach  <- st_filter(inat_sf, aoi_buf)
  trees_beach <- st_filter(trees,   aoi_buf)

  # --- save for reuse ---
  st_write(inat_beach,  inat_gj,  delete_dsn = TRUE, quiet = TRUE)
  st_write(trees_beach, tree_gj,  delete_dsn = TRUE, quiet = TRUE)
  st_write(aoi_buf,     aoi_gj,   delete_dsn = TRUE, quiet = TRUE)
  msg("ðŸ’¾ Saved GeoJSON to outputs/ for future runs.")
}

```

#3. Quick sizes
```{r}
tibble(
dataset = c("iNat (AOI)","Trees (AOI)"),
rows    = c(nrow(inat_beach), nrow(trees_beach))
)

```

#4. Top species & observers
```{r}
top_species <- inat_beach %>%
count(scientific_name, sort = TRUE) %>%
slice_head(n = 10)

top_observers <- inat_beach %>%
count(user_login, sort = TRUE) %>%
slice_head(n = 10)

top_species
top_observers

readr::write_csv(top_species,  file.path(OUT_DIR, "top_species.csv"))
readr::write_csv(top_observers,file.path(OUT_DIR, "top_observers.csv"))

```

#5. Temporal pattern (monthly)
```{r}
if ("observed_on" %in% names(inat_beach)) {
monthly <- inat_beach %>%
mutate(date = as.Date(observed_on)) %>%
filter(!is.na(date)) %>%
count(month = lubridate::floor_date(date, unit = "month"))

ggplot(monthly, aes(month, n)) +
geom_col() +
labs(x = "Month", y = "Observations", title = "iNaturalist observations per month") +
theme_minimal()
}

```

#6. Map â€” heat & layers
```{r}
leaflet(options = leafletOptions(minZoom = 10)) %>%
addProviderTiles("CartoDB.Positron") %>%
addPolygons(data = aoi_buf, label = "AOI (BIA âˆª Woodbine) 30m buffer",
color = "#444", weight = 2, fillOpacity = 0.05) %>%
addCircleMarkers(data = inat_beach, radius = 2, color = "blue", stroke = FALSE,
fillOpacity = 0.8, label = ~scientific_name, group = "iNaturalist") %>%
addCircleMarkers(data = trees_beach, radius = 2, color = "green", stroke = FALSE,
fillOpacity = 0.8, group = "Trees") %>%
addLayersControl(overlayGroups = c("iNaturalist","Trees"),
options = layersControlOptions(collapsed = FALSE)) %>%
addLegend("bottomright", colors=c("blue","green"), labels=c("iNaturalist","Trees"), title="Legend")

```

#7. Summary table (for report)
```{r}
species_n <- if ("scientific_name" %in% names(inat_beach))
n_distinct(inat_beach$scientific_name) else NA_integer_

AREA_CRS <- 32617
area_ha <- aoi_buf %>% st_transform(AREA_CRS) %>% st_area() %>% as.numeric() / 10000

summary_tbl <- tibble(
total_obs      = nrow(inat_beach),
unique_species = species_n,
tree_points    = nrow(trees_beach),
area_ha        = round(sum(area_ha), 2),
species_per_ha = round(species_n / sum(area_ha), 3)
)

summary_tbl
readr::write_csv(summary_tbl, file.path(OUT_DIR, "bio_summary_final.csv"))

```








